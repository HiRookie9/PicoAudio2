#defaults:
#  - data@test_data_dict: test

exp_dir: /hpc_stor03/sjtu_home/zihao.zheng/x_to_audio_generation/exp/pico_merge_infer_non_4gpu
ckpt_dir : /hpc_stor03/sjtu_home/zihao.zheng/x_to_audio_generation/exp/pico_merge_infer_non_4gpu/checkpoints/epoch_54
#sample_rate: 24000 # for training dataset config parsing

test_dataloader:
  _target_: torch.utils.data.DataLoader
  #dataset: ${test_data_dict.data_list.0}
  dataset:
    _target_: data_module.pico_dataset.Text_Onset_2_Audio_Dataset
    jsonl_file : /hpc_stor03/sjtu_home/zihao.zheng/data/audiocaps_v2/json/test/test_data_post_new.jsonl
    target_sr: 24000
  batch_size: 1 # per device batch size
  shuffle: False
  num_workers: 4
  collate_fn:
    _target_: data_module.collate_function.PaddingCollate
    pad_keys: []

wav_dir: test_data_post_new_54_7.5
noise_scheduler:
  type: DDIMScheduler
  name: "/hpc_stor03/sjtu_home/yaoyun.zhang/model_ckpts/stabilityai-stable-diffusion-2-1"

latent_shape: [128, 500]
num_steps: 50
guidance_scale: 7.5
use_gt_duration: true
#downsampling_ratio: 480